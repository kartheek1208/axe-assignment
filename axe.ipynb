{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ks-YEonqBcvI"
      },
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# 1) Install dependencies\n",
        "# -------------------------\n",
        "# Run this cell in Colab to install required libraries\n",
        "# (requests and jsonschema are small and standard)\n",
        "\n",
        "!pip install --quiet requests jsonschema"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 2) Imports and config\n",
        "# -------------------------\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "import requests\n",
        "from jsonschema import validate, ValidationError"
      ],
      "metadata": {
        "id": "0P4gIJQQBjgw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"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\")\n",
        "GROQ_BASE = 'https://api.groq.com/openai/v1'  # Groq OpenAI-compatible base URL\n",
        "\n",
        "if GROQ_API_KEY in (None, '', '<PUT_YOUR_KEY_IN_ENV>'):\n",
        "    print(\"WARNING: GROQ_API_KEY not set. Replace with your key via environment variable before running requests.\")\n",
        "\n",
        "HEADERS = {\n",
        "    'Authorization': f'Bearer {GROQ_API_KEY}',\n",
        "    'Content-Type': 'application/json'\n",
        "}"
      ],
      "metadata": {
        "id": "5r5pTFr4Bo9U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Utility: call Groq/OpenAI-compatible chat completions\n",
        "# -------------------------\n",
        "\n",
        "def groq_chat(messages: List[Dict[str,str]], model: str = 'openai/gpt-oss-20b',\n",
        "              functions: Optional[List[Dict[str,Any]]] = None,\n",
        "              function_call: Optional[Any] = None,\n",
        "              max_tokens: int = 512) -> Dict[str,Any]:\n",
        "    \"\"\"\n",
        "    Simple POST to Groq OpenAI-compatible Chat Completions endpoint.\n",
        "    messages: list of {role: 'user'|'assistant'|'system', 'content': str}\n",
        "    functions: optional list of function descriptors (for function calling)\n",
        "    function_call: 'auto' or {'name': 'func_name'} or None\n",
        "    \"\"\"\n",
        "    body = {\n",
        "        'model': model,\n",
        "        'messages': messages,\n",
        "        'max_tokens': max_tokens,\n",
        "    }\n",
        "    if functions is not None:\n",
        "        body['functions'] = functions\n",
        "    if function_call is not None:\n",
        "        body['function_call'] = function_call\n",
        "\n",
        "    url = f\"{GROQ_BASE}/chat/completions\"\n",
        "    resp = requests.post(url, headers=HEADERS, json=body, timeout=60)\n",
        "    try:\n",
        "        resp.raise_for_status()\n",
        "    except Exception as e:\n",
        "        print('API error:', e, resp.text[:500])\n",
        "        raise\n",
        "    return resp.json()"
      ],
      "metadata": {
        "id": "YPawEEOWB2sG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 4) Conversation history manager with summarization\n",
        "# -------------------------\n",
        "class ConversationHistory:\n",
        "    def __init__(self, summarization_model: str = 'openai/gpt-oss-20b',\n",
        "                 summary_trigger: int = 3):\n",
        "        \"\"\"summary_trigger: perform summarization after this many new user messages (k)\n",
        "        summarization_model: model used when calling the API for summarization\n",
        "        \"\"\"\n",
        "        self.history: List[Dict[str,str]] = []\n",
        "        self.summarized_text: Optional[str] = None\n",
        "        self.runs_since_summary = 0\n",
        "        self.summary_trigger = summary_trigger\n",
        "        self.summarization_model = summarization_model\n",
        "\n",
        "    def add_message(self, role: str, content: str):\n",
        "        assert role in ('user','assistant','system')\n",
        "        self.history.append({'role': role, 'content': content})\n",
        "        if role == 'user':\n",
        "            self.runs_since_summary += 1\n",
        "\n",
        "    def truncate_by_turns(self, n_turns: int) -> List[Dict[str,str]]:\n",
        "        # Keep last n_turns messages (turn = single message in this simple impl)\n",
        "        return self.history[-n_turns:]\n",
        "\n",
        "    def truncate_by_chars(self, max_chars: int) -> List[Dict[str,str]]:\n",
        "        # Return most recent messages while total chars <= max_chars\n",
        "        out = []\n",
        "        total = 0\n",
        "        for msg in reversed(self.history):\n",
        "            l = len(msg['content'])\n",
        "            if total + l > max_chars and out:\n",
        "                break\n",
        "            out.insert(0, msg)\n",
        "            total += l\n",
        "        return out\n",
        "\n",
        "    def summarize_history(self) -> str:\n",
        "        \"\"\"Call Groq/OpenAI to get a concise summary of the conversation history.\n",
        "        Stores and returns the summary string.\n",
        "        \"\"\"\n",
        "        if not self.history:\n",
        "            return ''\n",
        "        prompt = (\n",
        "            'Summarize the following conversation history into a concise summary that captures the user intent, '\n",
        "            'key facts (names, contact info, locations, requests), and the assistant actions. Return the summary in plain text.'\n",
        "        )\n",
        "        messages = [{'role': 'system', 'content': prompt},\n",
        "                    {'role': 'user', 'content': '\\n\\n'.join([f\"{m['role']}: {m['content']}\" for m in self.history])}]\n",
        "        resp = groq_chat(messages, model=self.summarization_model, max_tokens=256)\n",
        "        # Groq's chat/completions response shape mirrors OpenAI. Extract the assistant text.\n",
        "        try:\n",
        "            text = resp['choices'][0]['message']['content']\n",
        "        except Exception:\n",
        "            text = ''\n",
        "        self.summarized_text = text.strip()\n",
        "        self.history = [{'role':'system','content':f\"[SUMMARY]: {self.summarized_text}\"}]\n",
        "        self.runs_since_summary = 0\n",
        "        return self.summarized_text\n",
        "\n",
        "    def maybe_summarize(self):\n",
        "        if self.runs_since_summary >= self.summary_trigger:\n",
        "            return self.summarize_history()\n",
        "        return None\n",
        "\n",
        "    def get_view(self, truncation: Optional[Dict[str,Any]] = None) -> List[Dict[str,str]]:\n",
        "        \"\"\"Return a view of the history according to truncation options.\n",
        "        truncation can be {'type':'turns', 'value':n} or {'type':'chars','value':max_chars}\n",
        "        \"\"\"\n",
        "        if truncation is None:\n",
        "            return self.history\n",
        "        ttype = truncation.get('type')\n",
        "        val = truncation.get('value')\n",
        "        if ttype == 'turns':\n",
        "            return self.truncate_by_turns(val)\n",
        "        elif ttype == 'chars':\n",
        "            return self.truncate_by_chars(val)\n",
        "        else:\n",
        "            return self.history"
      ],
      "metadata": {
        "id": "fl6tDJC9B7fo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 5) Demonstration: feed sample conversations and show outputs\n",
        "# -------------------------\n",
        "# We'll create a small driver that simulates user-assistant exchanges and shows how summarization triggers\n",
        "\n",
        "SAMPLES = [\n",
        "    [\n",
        "        (\"user\",\"Hi, I'm Asha and I'm planning an event in Bangalore next month.\"),\n",
        "        (\"assistant\",\"Nice! What date and what kind of event?\"),\n",
        "        (\"user\",\"It's a tech meetup on 10th Oct, expecting 150 attendees. My email is asha@example.com.\"),\n",
        "    ],\n",
        "    [\n",
        "        (\"user\",\"Hey, I'm Rahul from Pune. My phone is +91-9876543210. I need help with dataset preprocessing.\"),\n",
        "        (\"assistant\",\"Sure Rahul â€” what format is your data?\"),\n",
        "        (\"user\",\"CSV with 10k rows, missing values in age and salary columns.\"),\n",
        "    ],\n",
        "    [\n",
        "        (\"user\",\"Hello, name's Priya. I want to buy a laptop for ML, budget 90k INR, location Hyderabad.\"),\n",
        "        (\"assistant\",\"Got it. Do you prefer NVIDIA GPUs?\"),\n",
        "        (\"user\",\"Yes, RTX 4060 if possible.\")\n",
        "    ]\n",
        "]\n",
        "\n",
        "# Demonstration driver\n",
        "hist = ConversationHistory(summary_trigger=3)\n",
        "\n",
        "print('Feeding sample conversations...')\n",
        "for idx, conv in enumerate(SAMPLES):\n",
        "    print(f'--- Conversation group {idx+1} ---')\n",
        "    for role, text in conv:\n",
        "        hist.add_message(role, text)\n",
        "    # Show truncation views\n",
        "    print('Last 4 turns view:')\n",
        "    view = hist.get_view({'type':'turns','value':4})\n",
        "    for m in view:\n",
        "        print(f\"{m['role']}: {m['content']}\")\n",
        "    print('\\nLast 120 chars view:')\n",
        "    view2 = hist.get_view({'type':'chars','value':120})\n",
        "    for m in view2:\n",
        "        print(f\"{m['role']}: {m['content']}\")\n",
        "    # Maybe summarize\n",
        "    s = hist.maybe_summarize()\n",
        "    if s:\n",
        "        print('\\n[Summarized after trigger]')\n",
        "        print(s)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_I8J4_BB_pn",
        "outputId": "71578c43-cd46-4e8e-e51c-e094d184144a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feeding sample conversations...\n",
            "--- Conversation group 1 ---\n",
            "Last 4 turns view:\n",
            "user: Hi, I'm Asha and I'm planning an event in Bangalore next month.\n",
            "assistant: Nice! What date and what kind of event?\n",
            "user: It's a tech meetup on 10th Oct, expecting 150 attendees. My email is asha@example.com.\n",
            "\n",
            "Last 120 chars view:\n",
            "user: It's a tech meetup on 10th Oct, expecting 150 attendees. My email is asha@example.com.\n",
            "\n",
            "\n",
            "--- Conversation group 2 ---\n",
            "Last 4 turns view:\n",
            "user: It's a tech meetup on 10th Oct, expecting 150 attendees. My email is asha@example.com.\n",
            "user: Hey, I'm Rahul from Pune. My phone is +91-9876543210. I need help with dataset preprocessing.\n",
            "assistant: Sure Rahul â€” what format is your data?\n",
            "user: CSV with 10k rows, missing values in age and salary columns.\n",
            "\n",
            "Last 120 chars view:\n",
            "assistant: Sure Rahul â€” what format is your data?\n",
            "user: CSV with 10k rows, missing values in age and salary columns.\n",
            "\n",
            "\n",
            "--- Conversation group 3 ---\n",
            "Last 4 turns view:\n",
            "system: [SUMMARY]: \n",
            "user: Hello, name's Priya. I want to buy a laptop for ML, budget 90k INR, location Hyderabad.\n",
            "assistant: Got it. Do you prefer NVIDIA GPUs?\n",
            "user: Yes, RTX 4060 if possible.\n",
            "\n",
            "Last 120 chars view:\n",
            "assistant: Got it. Do you prefer NVIDIA GPUs?\n",
            "user: Yes, RTX 4060 if possible.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 6) Task 2: JSON Schema classification & function-calling demonstration\n",
        "# -------------------------\n",
        "# Define a JSON schema to extract five details: name, email, phone, location, age\n",
        "SCHEMA = {\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"name\": {\"type\": \"string\"},\n",
        "    \"email\": {\"type\": \"string\", \"format\": \"email\"},\n",
        "    \"phone\": {\"type\": \"string\"},\n",
        "    \"location\": {\"type\": \"string\"},\n",
        "    \"age\": {\"type\": [\"integer\",\"null\"]}\n",
        "  },\n",
        "  \"required\": [\"name\"]\n",
        "}\n",
        "\n",
        "# Define a function descriptor using OpenAI-style function calling for structured output\n",
        "FUNCTIONS = [\n",
        "    {\n",
        "        \"name\": \"extract_contact_info\",\n",
        "        \"description\": \"Extract contact information from the user's message in JSON matching the schema.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": \"Person's full name\"},\n",
        "                \"email\": {\"type\": \"string\", \"description\": \"Email if present\"},\n",
        "                \"phone\": {\"type\": \"string\", \"description\": \"Phone number if present\"},\n",
        "                \"location\": {\"type\": \"string\", \"description\": \"Location or city if present\"},\n",
        "                \"age\": {\"type\": [\"integer\",\"null\"], \"description\": \"Age if present\"}\n",
        "            },\n",
        "            \"required\": [\"name\"]\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "7ksK_GR3CC06"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample chats for extraction\n",
        "EXTRACTION_SAMPLES = [\n",
        "    \"Hi, I'm Asha Patel from Bangalore. You can contact me at asha.patel@example.com or +91 90123 45678. I'm 28.\",\n",
        "    \"Rahul here. my email rahul92@gmail.com. based in Pune. phone 9876543210.\",\n",
        "    \"This is Priya â€” planning to attend. No contact given yet.\"\n",
        "]\n",
        "\n",
        "# Helper: call model with function definitions and parse function response\n",
        "\n",
        "def extract_with_function_call(text: str) -> Dict[str,Any]:\n",
        "    messages = [\n",
        "        {\"role\":\"user\",\"content\": text}\n",
        "    ]\n",
        "    resp = groq_chat(messages, model='openai/gpt-oss-20b', functions=FUNCTIONS, function_call='auto', max_tokens=150)\n",
        "    # The model is expected to return a function call in choices[0].message\n",
        "    choice = resp['choices'][0]\n",
        "    msg = choice.get('message', {})\n",
        "    if msg.get('function_call'):\n",
        "        name = msg['function_call']['name']\n",
        "        args_str = msg['function_call'].get('arguments','{}')\n",
        "        try:\n",
        "            args = json.loads(args_str)\n",
        "        except Exception:\n",
        "            args = {}\n",
        "        return {'function': name, 'args': args, 'raw': msg}\n",
        "    else:\n",
        "        # Fallback: parse assistant text as JSON\n",
        "        content = msg.get('content','')\n",
        "        try:\n",
        "            parsed = json.loads(content)\n",
        "            return {'function': None, 'args': parsed, 'raw': msg}\n",
        "        except Exception:\n",
        "            return {'function': None, 'args': {}, 'raw': msg}\n",
        "\n",
        "# Run extraction and validate\n",
        "for sample in EXTRACTION_SAMPLES:\n",
        "    print('Sample:', sample)\n",
        "    out = extract_with_function_call(sample)\n",
        "    args = out['args']\n",
        "    print('Model-extracted args:', args)\n",
        "    try:\n",
        "        validate(instance=args, schema=SCHEMA)\n",
        "        print('Validation: PASS')\n",
        "    except ValidationError as ve:\n",
        "        print('Validation: FAIL ->', ve.message)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5caZaIGCZQx",
        "outputId": "775c1488-270d-41b2-aff4-9088f8aec0c4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: Hi, I'm Asha Patel from Bangalore. You can contact me at asha.patel@example.com or +91 90123 45678. I'm 28.\n",
            "Model-extracted args: {'age': 28, 'email': 'asha.patel@example.com', 'location': 'Bangalore', 'name': 'Asha Patel', 'phone': '+91 90123 45678'}\n",
            "Validation: PASS\n",
            "\n",
            "\n",
            "Sample: Rahul here. my email rahul92@gmail.com. based in Pune. phone 9876543210.\n",
            "Model-extracted args: {'email': 'rahul92@gmail.com', 'location': 'Pune', 'name': 'Rahul', 'phone': '9876543210'}\n",
            "Validation: PASS\n",
            "\n",
            "\n",
            "Sample: This is Priya â€” planning to attend. No contact given yet.\n",
            "Model-extracted args: {}\n",
            "Validation: FAIL -> 'name' is a required property\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}